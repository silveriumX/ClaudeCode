# Интеграция источников контекста (Fireflies, чаты и др.) без сжигания токенов

Отчёт по исследованию через EXA: как в экосистеме Cursor строят «личную ОС» с интеграцией внешних источников контекста, не загружая в промпт миллиарды токенов.

---

## 1. Dynamic context discovery (Cursor, январь 2026)

**Источник:** [cursor.com/blog/dynamic-context-discovery](https://cursor.com/blog/dynamic-context-discovery)

Идея: **статический контекст** (всё всегда в промпте) сжигает токены; **динамическое обнаружение контекста** — агент подтягивает только нужное.

### Принципы

- Давать агенту **меньше деталей заранее**, чтобы он сам подтягивал релевантный контекст.
- В контекст попадает **только необходимая** информация → меньше токенов и меньше шума.

### Приёмы, которые использует Cursor

| Приём | Описание | Эффект |
|-------|----------|--------|
| **Длинные ответы инструментов → в файлы** | Ответы MCP/shell не вставляются целиком в чат. Пишутся в файл; агент по необходимости читает (`tail`, чтение куска). | Нет потери данных при обрезке, но и нет мегабайт в контексте. |
| **История чата как файлы** | При суммаризации агент получает ссылку на файл истории. Если нужны детали — ищет в файле. | В контексте только суммари, детали — по запросу. |
| **Skills** | В системный промпт попадают только имена/описания скиллов. Полный текст скилла агент подтягивает через grep / semantic search при необходимости. | Тяжёлые инструкции не грузятся заранее. |
| **MCP: только нужные инструменты** | Описания MCP-инструментов **не** кладутся целиком в промпт. Синхронизируются в папку (по серверам); в промпт попадает небольшой статический кусок (названия инструментов). Агент подглядывает описание, когда задача требует вызова инструмента. | В A/B тесте Cursor: **снижение токенов агента на 46,9%** в прогонах с вызовом MCP. |
| **Терминал как файлы** | Вывод терминала пишется в файловую систему. Агент по запросу ищет (grep) нужный кусок вместо того, чтобы тащить весь лог. | Контекст только по релевантным строкам. |

Итог: контекст — **по запросу** (файлы, поиск, список инструментов), а не «всё сразу» в промпте.

---

## 2. RAG вместо дампа в контекст (как у Cursor с кодом)

**Источник:** [Towards Data Science — How Cursor Actually Indexes Your Codebase](https://towardsdatascience.com/how-cursor-actually-indexes-your-codebase/)

Для кода Cursor не передаёт весь репозиторий в LLM. Используется **RAG**:

1. **Чанкинг** — разбиение кода на осмысленные куски (функции, классы).
2. **Эмбеддинги + метаданные** — векторное представление и путь/строки хранятся (в т.ч. в Turbopuffer).
3. **Поиск в момент запроса** — по запросу пользователя ищутся релевантные чанки, по метаданным достаётся **только нужный код** с диска и передаётся в контекст.

Для внешних источников (Fireflies, чаты, документация) та же схема:

- **Индексировать** (чанки + эмбеддинги) транскрипты, чаты, заметки.
- **Не** загружать все транскрипты в чат.
- По запросу («что решили про X?», «встреча с Мариной») — **семантический поиск** → достать только релевантные фрагменты → отдать их в контекст.

Так «сжигается» только объём выбранных чанков, а не все встречи/чаты разом.

---

## 3. MCP: инструменты по требованию

**Источник:** Cursor Docs (MCP), блог про dynamic context discovery.

- MCP даёт доступ к внешним системам (Fireflies, БД, чаты и т.д.).
- Проблема: если в промпт класть **все** описания инструментов всех MCP-серверов — контекст раздувается.
- Решение в Cursor: описания MCP-инструментов хранятся **в папках** (по серверам). В промпт попадает минимум (например, имена). Агент **смотрит описание** только когда решает вызвать инструмент.
- Для данных (Fireflies, чаты): не вызывать «скачай все транскрипты» одним махом. Либо:
  - MCP-инструмент «поиск по транскриптам» (по запросу возвращает только совпадения), или
  - Локальная выгрузка в файлы + индексация (RAG), а в чат попадает только результат поиска.

---

## 4. Практические схемы для Fireflies и чатов

### Вариант A: Всё в файлы, контекст по запросу

- **Вне Cursor:** скрипт/интеграция по расписанию забирает из Fireflies (и при желании чаты) новые встречи/переписки и пишет в `Fireflies/*.md` (или в БД/файлы).
- **В Cursor:** агент **не** вызывает MCP «получить все транскрипты». Пользователь спрашивает про встречу → агент читает уже сохранённый файл (или список файлов) и при необходимости делает семантический поиск по папке.
- Токены: только на прочитанные файлы и поиск, а не на массовую загрузку через MCP.

### Вариант B: Минимум в промпте, MCP по одной встрече

- В контекст даётся только **список** встреч (лёгкий вызов `get_transcripts` или локальный индекс).
- Полный транскрипт через MCP запрашивается **только для одной** выбранной встречи (по ID/дате/названию), когда пользователь явно про неё спрашивает.
- Длинный ответ MCP можно не целиком вставлять в чат, а писать во временный файл и давать агенту команду «прочитай файл X» (как в dynamic context discovery).

### Вариант C: RAG поверх своих данных

- Транскрипты (и при желании чаты) периодически выгружаются и **индексируются** (чанки + эмбеддинги, локально или в сервисе).
- В Cursor: либо MCP-инструмент «поиск по индексу» (возвращает только релевантные цитаты), либо семантический поиск по папке с сохранёнными файлами.
- В контекст попадают только найденные фрагменты, а не все встречи.

---

## 5. Краткий чек-лист

- **Не грузить всё:** ни все транскрипты, ни все чаты разом в один запрос.
- **Файлы вместо огромных ответов:** длинные ответы MCP/скриптов писать в файл, агент читает по необходимости (tail, grep, read).
- **Списки и индексы в промпте:** только имена/ID/даты; полное содержимое — по запросу или через поиск.
- **MCP по требованию:** вызывать тяжёлые инструменты (полный транскрипт) только когда запрос пользователя к этому относится.
- **RAG для больших объёмов:** индексировать Fireflies/чаты/документы, в контекст подавать только релевантные чанки.
- **Локальная синхронизация:** выносить «тяжёлую» выгрузку из Cursor в скрипты/кроны; в чате работать уже с файлами и индексами.

---

## 6. Как это делают в экосистеме: «личная ОС» на Cursor

**Источники:** EXA (LinkedIn, Cursor Docs, Pieces, Apify, Developer Toolkit, MCP-туториалы). Январь 2026.

### Идея «Personal OS» поверх Cursor/Claude Code

- **Claude Code / Cursor как слой ОС:** не просто «агент для кода», а агентная прослойка поверх всего компьютера — код, встречи, чаты, документация, календарь, почта. Контекст собирается из разных источников по запросу.
- **Фокус на контексте:** «Working with AI models is all about **managing the context you provide it**» (Cursor Learn). Качество выхода зависит от того, что именно попадает в контекст и в каком объёме.

### Интеграции без «всего сразу» в промпте

| Подход | Кто/где | Суть |
|--------|---------|------|
| **Pieces MCP + Cursor** | [Pieces docs](https://docs.pieces.app/products/mcp/cursor) | «In-IDE chatbot that **knows more than your project**» — подтягивают workflow-контекст (PR, коммиты, чаты), но не дампом, а через MCP по запросу. |
| **Apify MCP + Cursor** | [Apify Blog](https://blog.apify.com/how-to-add-mcp-server-to-cursor/) | Данные (скрапинг, конкуренты, соцсети) не копируются в чат целиком. Агент **вызывает инструменты по шагам**: сначала поиск/скрапинг, потом анализ только нужного. «No context switching» = один чат, но контекст растёт только от выбранных вызовов. |
| **Context7, Puppeteer, DB** | [Developer Toolkit](https://developertoolkit.ai/en/cursor-ide/quick-start/mcp-setup/) | Документация (Context7), браузер, БД — отдельные MCP. Рекомендация: **2–3 MCP на старт**, не включать всё сразу; conditional/project-specific MCP, чтобы не раздувать контекст. |
| **MCP как оркестрация** | [Medium — MCP workflow](https://sambit9238.medium.com/mcp-in-action-end-to-end-assistant-workflow-explained-f3ead1aab82f) | Один запрос («Plan my Saturday») → сервер даёт LLM **список инструментов** (email, calendar, gdocs). Модель **сама выбирает**, какие вызвать и с какими аргументами. В контекст попадают только **результаты вызовов**, а не все системы разом. |
| **Cursor Enterprise** | [Cursor Docs](https://cursor.com/docs/enterprise/model-and-integration-management) | Управление моделями и интеграциями (Slack, Linear, GitHub и т.д.) — контекст из интеграций подтягивается в рамках правил и лимитов, а не «всё подряд». |

### Общий принцип

Не загружать в один промпт все источники (Fireflies, чаты, документы, MCP-описания). Давать агенту **каталог возможностей** (имена инструментов, списки встреч/файлов) и позволять **динамически подтягивать** только то, что нужно для текущего шага — в точности как в Cursor dynamic context discovery.

---

*Исследование проведено через EXA (Cursor + Fireflies, dynamic context, MCP, RAG, Pieces, Apify, Developer Toolkit). Январь 2026.*
