#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ò–º–ø–æ—Ä—Ç PDF –≤—ã–ø–∏—Å–æ–∫ –ª–∏—á–Ω—ã—Ö —Å—á–µ—Ç–æ–≤ —Ñ–∏–∑–ª–∏—Ü.

–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –±–∞–Ω–∫–∏: –ê–ª—å—Ñ–∞–ë–∞–Ω–∫, –í–¢–ë, –°–±–µ—Ä–±–∞–Ω–∫, –¢-–ë–∞–Ω–∫.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    # –û–¥–∏–Ω —Ñ–∞–π–ª
    python -X utf8 import_personal.py "–í—ã–ø–∏—Å–∫–∏ —Å —Å—á–µ—Ç–æ–≤ —Ñ–∏–∑–ª–∏—Ü–∞/–ê–ª—å—Ñ–∞.pdf"

    # –ù–µ—Å–∫–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤
    python -X utf8 import_personal.py "–í—ã–ø–∏—Å–∫–∏ —Å —Å—á–µ—Ç–æ–≤ —Ñ–∏–∑–ª–∏—Ü–∞/–ê–ª—å—Ñ–∞.pdf" "–í—ã–ø–∏—Å–∫–∏ —Å —Å—á–µ—Ç–æ–≤ —Ñ–∏–∑–ª–∏—Ü–∞/–í–¢–ë.pdf"

    # –ü–∞–ø–∫–∞ —Ü–µ–ª–∏–∫–æ–º
    python -X utf8 import_personal.py --folder "–í—ã–ø–∏—Å–∫–∏ —Å —Å—á–µ—Ç–æ–≤ —Ñ–∏–∑–ª–∏—Ü–∞/" --out personal_all.xlsx

    # –£–∫–∞–∑–∞—Ç—å –±–∞–Ω–∫ —è–≤–Ω–æ (–µ—Å–ª–∏ –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç)
    python -X utf8 import_personal.py "–ê–ª—å—Ñ–∞.pdf" --bank alfa

–í—ã—Ö–æ–¥–Ω–æ–π Excel (4 –ª–∏—Å—Ç–∞):
    üìä –°–≤–æ–¥–∫–∞          ‚Äî –ø–æ –±–∞–Ω–∫–∞–º –∏ –º–µ—Å—è—Ü–∞–º (–ø—Ä–∏—Ö–æ–¥/—Ä–∞—Å—Ö–æ–¥)
    üìã –ñ—É—Ä–Ω–∞–ª          ‚Äî –≤—Å–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –∏–∑ –≤—Å–µ—Ö PDF
    üîç –†—É—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ ‚Äî –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å confidence='manual'
    üìà –ö—Ä—É–ø–Ω—ã–µ —Å—É–º–º—ã   ‚Äî –æ–ø–µ—Ä–∞—Ü–∏–∏ > 50 000 —Ä—É–±.
"""

import argparse
import glob
import io
import logging
import re
import sys
from pathlib import Path

if sys.stdout.encoding != "utf-8":
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding="utf-8", errors="replace")
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding="utf-8", errors="replace")

import pandas as pd

sys.path.insert(0, str(Path(__file__).parent))

from src.personal_parsers import detect_pdf_bank, parse_personal_pdf, PDF_PARSERS

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)

# ‚îÄ‚îÄ‚îÄ –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

BANK_NAMES = {
    "alfa":  "–ê–ª—å—Ñ–∞–ë–∞–Ω–∫",
    "vtb":   "–í–¢–ë",
    "sber":  "–°–±–µ—Ä–±–∞–Ω–∫",
    "tbank": "–¢-–ë–∞–Ω–∫",
}

# ‚îÄ‚îÄ‚îÄ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –æ–ø–µ—Ä–∞—Ü–∏–π –ª–∏—á–Ω–æ–≥–æ —Å—á—ë—Ç–∞ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

_MODULBANK_RE = re.compile(r"–ú–æ–¥—É–ª—å–±–∞–Ω–∫|–ú–æ—Å–∫–æ–≤—Å–∫–∏–π –§–∏–ª–∏–∞–ª –ê–û –ö–ë", re.IGNORECASE)
_INTERNAL_RE  = re.compile(
    r"—Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å—Ä–µ–¥—Å—Ç–≤|–≤–Ω—É—Ç—Ä–∏–±–∞–Ω–∫–æ–≤—Å–∫|–≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –ø–µ—Ä–µ–≤–æ–¥|–ø–µ—Ä–µ–≤–æ–¥ –º–µ–∂–¥—É —Å—á–µ—Ç",
    re.IGNORECASE,
)
_OWNER_RE     = re.compile(r"–ü–∏—Ä–æ–∂–∫–æ–≤", re.IGNORECASE)
_P2P_RE       = re.compile(r"p2p|bybit|binance|htx|okx|bitpapa|usdt|btc|–∫—Ä–∏–ø—Ç|–±–∏—Ç–∫–æ–π–Ω|—Ç–æ–∫–µ–Ω", re.IGNORECASE)
_ATM_RE       = re.compile(r"–≤—ã–¥–∞—á–∞ –Ω–∞–ª–∏—á–Ω—ã—Ö|—Å–Ω—è—Ç–∏–µ|–±–∞–Ω–∫–æ–º–∞—Ç|\bATM\b", re.IGNORECASE)
_BANK_FEE_RE  = re.compile(r"–∫–æ–º–∏—Å—Å–∏—è|–ø–∞–∫–µ—Ç —É—Å–ª—É–≥|–æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ —Å—á—ë—Ç|–ø–æ–¥–ø–∏—Å–∫–∞ –í–¢–ë|–í–¢–ë –ü–ª—é—Å", re.IGNORECASE)


def _classify_personal(row: pd.Series) -> dict:
    """
    –£–ø—Ä–æ—â—ë–Ω–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –æ–ø–µ—Ä–∞—Ü–∏–∏ –ª–∏—á–Ω–æ–≥–æ —Å—á—ë—Ç–∞.

    –ö–ª—é—á–µ–≤—ã–µ —Ç–∏–ø—ã:
      –ü–µ—Ä–µ–≤–æ–¥ –∏–∑ –±–∏–∑–Ω–µ—Å–∞ ‚Äî –ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏–µ —Å —Ä/—Å –ú–æ–¥—É–ª—å–ë–∞–Ω–∫–∞
      –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –ø–µ—Ä–µ–≤–æ–¥ ‚Äî –º–µ–∂–¥—É —Å–≤–æ–∏–º–∏ —Å—á–µ—Ç–∞–º–∏ (—Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å—Ä–µ–¥—Å—Ç–≤)
      P2P (–∫—Ä–∏–ø—Ç–∞)       ‚Äî –í–ê–ñ–ù–û: –Ω–µ —Ä–∞—Å—Ö–æ–¥ (—Å–º. HANDOFF.md ¬ß–ü—Ä–∞–≤–∏–ª–∞)
      –°–Ω—è—Ç–∏–µ –Ω–∞–ª–∏—á–Ω—ã—Ö    ‚Äî –±–∞–Ω–∫–æ–º–∞—Ç
      –ë–∞–Ω–∫–æ–≤—Å–∫–∞—è –∫–æ–º–∏—Å—Å–∏—è
      –î–æ—Ö–æ–¥ / –†–∞—Å—Ö–æ–¥     ‚Äî –ø—Ä–æ—á–µ–µ (manual)
    """
    purpose   = str(row.get("purpose", ""))
    cp        = str(row.get("counterparty", ""))
    full      = purpose + " " + cp
    is_income = bool(row.get("is_income", False))

    # –ü–æ—Å—Ç—É–ø–ª–µ–Ω–∏–µ —Å –±–∏–∑–Ω–µ—Å —Ä/—Å –ú–æ–¥—É–ª—å–ë–∞–Ω–∫–∞
    if is_income and _MODULBANK_RE.search(full):
        return {"type": "–ü–µ—Ä–µ–≤–æ–¥ –∏–∑ –±–∏–∑–Ω–µ—Å–∞", "category": "–ü–æ—Å—Ç—É–ø–ª–µ–Ω–∏–µ —Å —Ä/—Å", "confidence": "auto"}

    # –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–¥—ã (—Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞ / –º–µ–∂–¥—É —Å–≤–æ–∏–º–∏ —Å—á–µ—Ç–∞–º–∏)
    if _INTERNAL_RE.search(full):
        return {"type": "–í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –ø–µ—Ä–µ–≤–æ–¥", "category": "–ú–µ–∂–¥—É —Å–≤–æ–∏–º–∏ —Å—á–µ—Ç–∞–º–∏", "confidence": "auto"}

    # –ü–µ—Ä–µ–≤–æ–¥ —Å–∞–º–æ–π —Å–µ–±–µ (–∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç = –≤–ª–∞–¥–µ–ª–µ—Ü)
    if _OWNER_RE.search(cp):
        return {"type": "–í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –ø–µ—Ä–µ–≤–æ–¥", "category": "–ú–µ–∂–¥—É —Å–≤–æ–∏–º–∏ —Å—á–µ—Ç–∞–º–∏", "confidence": "auto"}

    # P2P / –∫—Ä–∏–ø—Ç–∞ ‚Äî –ù–ï —Ä–∞—Å—Ö–æ–¥! (—Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞—Å—Ö–æ–¥ —É–∂–µ –≤ FinanceBot)
    if _P2P_RE.search(full):
        return {"type": "P2P (–∫—Ä–∏–ø—Ç–∞)", "category": "–ü–æ–∫—É–ø–∫–∞ USDT", "confidence": "auto"}

    # –°–Ω—è—Ç–∏–µ –Ω–∞–ª–∏—á–Ω—ã—Ö
    if _ATM_RE.search(full):
        return {"type": "–°–Ω—è—Ç–∏–µ –Ω–∞–ª–∏—á–Ω—ã—Ö", "category": "–ù–∞–ª–∏—á–Ω—ã–µ", "confidence": "auto"}

    # –ë–∞–Ω–∫–æ–≤—Å–∫–∏–µ –∫–æ–º–∏—Å—Å–∏–∏
    if _BANK_FEE_RE.search(full):
        return {"type": "–†–∞—Å—Ö–æ–¥", "category": "–ë–∞–Ω–∫–æ–≤—Å–∫–∏–µ –∫–æ–º–∏—Å—Å–∏–∏", "confidence": "auto"}

    # –ü—Ä–æ—á–∏–π –¥–æ—Ö–æ–¥
    if is_income:
        return {"type": "–î–æ—Ö–æ–¥", "category": "–ü—Ä–æ—á–µ–µ", "confidence": "manual"}

    # –ü—Ä–æ—á–∏–π —Ä–∞—Å—Ö–æ–¥
    return {"type": "–†–∞—Å—Ö–æ–¥", "category": "–ü—Ä–æ—á–µ–µ", "confidence": "manual"}


# ‚îÄ‚îÄ‚îÄ –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def build_journal(df: pd.DataFrame, bank_name: str) -> pd.DataFrame:
    """–î–æ–±–∞–≤–ª—è–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ –±–∞–Ω–∫–∞ –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∫ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º—É DataFrame."""
    results = [_classify_personal(row) for _, row in df.iterrows()]
    j = df.copy()
    j["_–±–∞–Ω–∫"]          = bank_name
    j["_—Ç–∏–ø"]           = [r["type"]       for r in results]
    j["_–∫–∞—Ç–µ–≥–æ—Ä–∏—è"]     = [r["category"]   for r in results]
    j["_–¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å"] = [r["confidence"] for r in results]

    return j[[
        "date", "_–±–∞–Ω–∫", "_—Ç–∏–ø", "_–∫–∞—Ç–µ–≥–æ—Ä–∏—è",
        "amount_in", "amount_out", "amount",
        "counterparty", "purpose", "doc_num", "_–¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å",
    ]].rename(columns={
        "date":           "–î–∞—Ç–∞",
        "_–±–∞–Ω–∫":          "–ë–∞–Ω–∫",
        "_—Ç–∏–ø":           "–¢–∏–ø",
        "_–∫–∞—Ç–µ–≥–æ—Ä–∏—è":     "–ö–∞—Ç–µ–≥–æ—Ä–∏—è",
        "amount_in":      "–ü—Ä–∏—Ö–æ–¥",
        "amount_out":     "–†–∞—Å—Ö–æ–¥",
        "amount":         "–°—É–º–º–∞",
        "counterparty":   "–ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç",
        "purpose":        "–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ",
        "doc_num":        "–ù–æ–º–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞",
        "_–¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å": "–î–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å",
    })


def build_monthly_summary(journal: pd.DataFrame) -> pd.DataFrame:
    """–°–≤–æ–¥–∫–∞: –ø–æ –±–∞–Ω–∫–∞–º –∏ –º–µ—Å—è—Ü–∞–º ‚Äî –ø—Ä–∏—Ö–æ–¥ / —Ä–∞—Å—Ö–æ–¥ / –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ."""
    df = journal.copy()
    df["–ì–æ–¥"]   = df["–î–∞—Ç–∞"].dt.year
    df["–ú–µ—Å—è—Ü"] = df["–î–∞—Ç–∞"].dt.month

    rows = []
    for (bank, year, month), grp in df.groupby(["–ë–∞–Ω–∫", "–ì–æ–¥", "–ú–µ—Å—è—Ü"]):
        income   = grp[grp["–¢–∏–ø"].str.contains("–ü–µ—Ä–µ–≤–æ–¥ –∏–∑ –±–∏–∑–Ω–µ—Å–∞|–î–æ—Ö–æ–¥", na=False, regex=True)]["–°—É–º–º–∞"].sum()
        expense  = grp[grp["–¢–∏–ø"].str.contains("–†–∞—Å—Ö–æ–¥|–°–Ω—è—Ç–∏–µ –Ω–∞–ª–∏—á–Ω—ã—Ö", na=False, regex=True)]["–°—É–º–º–∞"].sum()
        internal = grp[grp["–¢–∏–ø"].str.contains("–í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π|P2P", na=False, regex=True)]["–°—É–º–º–∞"].sum()
        rows.append({
            "–ë–∞–Ω–∫":              bank,
            "–ì–æ–¥":               int(year),
            "–ú–µ—Å—è—Ü":             int(month),
            "–ü—Ä–∏—Ö–æ–¥":            round(income, 2),
            "–†–∞—Å—Ö–æ–¥":            round(expense, 2),
            "–í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ / P2P":  round(internal, 2),
            "–ö–æ–ª-–≤–æ –æ–ø–µ—Ä–∞—Ü–∏–π":   len(grp),
        })
    if not rows:
        return pd.DataFrame()
    return pd.DataFrame(rows).sort_values(["–ë–∞–Ω–∫", "–ì–æ–¥", "–ú–µ—Å—è—Ü"])


def build_large_transactions(journal: pd.DataFrame, threshold: float = 50_000) -> pd.DataFrame:
    """–û–ø–µ—Ä–∞—Ü–∏–∏ ‚â• threshold —Ä—É–±. ‚Äî –Ω—É–∂–¥–∞—é—Ç—Å—è –≤ —Ä—É—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–µ."""
    return (
        journal[journal["–°—É–º–º–∞"] >= threshold]
        .sort_values("–°—É–º–º–∞", ascending=False)
        .reset_index(drop=True)
    )


def export_to_excel(
    journal: pd.DataFrame,
    summary: pd.DataFrame,
    large: pd.DataFrame,
    output_path: Path,
) -> None:
    """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –≤—Å–µ —Ç–∞–±–ª–∏—Ü—ã –≤ Excel —Å –∞–≤—Ç–æ—à–∏—Ä–∏–Ω–æ–π –∫–æ–ª–æ–Ω–æ–∫."""
    manual = journal[journal["–î–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å"] == "manual"].copy()

    with pd.ExcelWriter(output_path, engine="openpyxl") as writer:
        for sheet_name, data in [
            ("üìä –°–≤–æ–¥–∫–∞",           summary),
            ("üìã –ñ—É—Ä–Ω–∞–ª",           journal),
            ("üîç –†—É—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞",  manual),
            ("üìà –ö—Ä—É–ø–Ω—ã–µ —Å—É–º–º—ã",    large),
        ]:
            data.to_excel(writer, sheet_name=sheet_name, index=False)

        # –ê–≤—Ç–æ-—à–∏—Ä–∏–Ω–∞ –∫–æ–ª–æ–Ω–æ–∫
        for ws in writer.sheets.values():
            for col in ws.columns:
                max_len = max(len(str(cell.value or "")) for cell in col)
                ws.column_dimensions[col[0].column_letter].width = min(max_len + 2, 60)

    logger.info(f"–û—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {output_path}")


def print_console_summary(summary: pd.DataFrame) -> None:
    """–í—ã–≤–æ–¥–∏—Ç —Å–≤–æ–¥–∫—É –≤ –∫–æ–Ω—Å–æ–ª—å."""
    if summary.empty:
        print("  (–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö)")
        return
    print(f"\n{'='*74}")
    print(f"  –°–≤–æ–¥–∫–∞ –ø–æ –ª–∏—á–Ω—ã–º —Å—á–µ—Ç–∞–º")
    print(f"{'='*74}")
    print(f"{'–ë–∞–Ω–∫':<12} {'–ü–µ—Ä–∏–æ–¥':<10} {'–ü—Ä–∏—Ö–æ–¥':>14} {'–†–∞—Å—Ö–æ–¥':>14} {'–í–Ω—É—Ç—Ä./P2P':>12}")
    print(f"{'-'*74}")
    for _, row in summary.iterrows():
        period = f"{row['–ì–æ–¥']}-{row['–ú–µ—Å—è—Ü']:02d}"
        print(
            f"{row['–ë–∞–Ω–∫']:<12} {period:<10} "
            f"{row['–ü—Ä–∏—Ö–æ–¥']:>14,.0f} "
            f"{row['–†–∞—Å—Ö–æ–¥']:>14,.0f} "
            f"{row['–í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ / P2P']:>12,.0f}"
        )
    totals = summary[["–ü—Ä–∏—Ö–æ–¥", "–†–∞—Å—Ö–æ–¥", "–í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ / P2P"]].sum()
    print(f"{'='*74}")
    print(
        f"{'–ò–¢–û–ì–û':<23} "
        f"{totals['–ü—Ä–∏—Ö–æ–¥']:>14,.0f} "
        f"{totals['–†–∞—Å—Ö–æ–¥']:>14,.0f} "
        f"{totals['–í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ / P2P']:>12,.0f}"
    )
    print(f"{'='*74}\n")


# ‚îÄ‚îÄ‚îÄ –°–±–æ—Ä —Ñ–∞–π–ª–æ–≤ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def collect_pdf_files(args: argparse.Namespace) -> list[Path]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–µ–¥—É–ø–ª–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ PDF –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
    paths: list[Path] = []

    if args.folder:
        folder = Path(args.folder)
        if not folder.is_dir():
            logger.error(f"–ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {folder}")
            sys.exit(1)
        paths.extend(sorted(folder.glob("*.pdf")))

    for pattern in (args.files or []):
        matched = glob.glob(pattern)
        if matched:
            paths.extend(Path(p) for p in sorted(matched))
        else:
            p = Path(pattern)
            if p.exists():
                paths.append(p)
            else:
                logger.warning(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {pattern}")

    # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø–æ—Ä—è–¥–∫–∞
    seen: set[Path] = set()
    result: list[Path] = []
    for p in paths:
        key = p.resolve()
        if key not in seen:
            seen.add(key)
            result.append(p)
    return result


# ‚îÄ‚îÄ‚îÄ –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def main() -> None:
    parser = argparse.ArgumentParser(
        description="–ò–º–ø–æ—Ä—Ç PDF –≤—ã–ø–∏—Å–æ–∫ –ª–∏—á–Ω—ã—Ö —Å—á–µ—Ç–æ–≤ (–ê–ª—å—Ñ–∞, –í–¢–ë, –°–±–µ—Ä, –¢-–ë–∞–Ω–∫)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__,
    )
    parser.add_argument(
        "files", nargs="*",
        help="PDF-—Ñ–∞–π–ª—ã (–º–æ–∂–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è wildcards)",
    )
    parser.add_argument(
        "--folder", default=None,
        help="–ü–∞–ø–∫–∞ ‚Äî –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Å–µ PDF –≤–Ω—É—Ç—Ä–∏",
    )
    parser.add_argument(
        "--bank", default="auto",
        choices=["auto"] + list(PDF_PARSERS),
        help="–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∑–∞–¥–∞—Ç—å –±–∞–Ω–∫ (default: auto)",
    )
    parser.add_argument(
        "--out", default="personal_journal.xlsx",
        help="–ò–º—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ Excel-—Ñ–∞–π–ª–∞ (default: personal_journal.xlsx)",
    )
    parser.add_argument(
        "--large-threshold", type=float, default=50_000,
        help="–ü–æ—Ä–æ–≥ –∫—Ä—É–ø–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π –≤ —Ä—É–±. (default: 50000)",
    )
    args = parser.parse_args()

    pdf_files = collect_pdf_files(args)
    if not pdf_files:
        logger.error("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ PDF. –£–∫–∞–∂–∏—Ç–µ —Ñ–∞–π–ª—ã –∏–ª–∏ --folder.")
        sys.exit(1)

    logger.info(f"–§–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(pdf_files)}")
    all_journals: list[pd.DataFrame] = []

    for pdf_path in pdf_files:
        try:
            bank_key  = args.bank if args.bank != "auto" else detect_pdf_bank(pdf_path)
            bank_name = BANK_NAMES.get(bank_key, bank_key.upper())
            logger.info(f"  ‚Üí {pdf_path.name} [{bank_name}]")

            df = parse_personal_pdf(pdf_path, bank=bank_key)
            if df.empty:
                logger.warning(f"    ‚ö† –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö: {pdf_path.name}")
                continue

            journal = build_journal(df, bank_name)
            all_journals.append(journal)
            logger.info(f"    ‚úì {len(df)} –æ–ø–µ—Ä–∞—Ü–∏–π")

        except Exception as exc:
            logger.error(f"  ‚úó {pdf_path.name}: {exc}", exc_info=True)

    if not all_journals:
        logger.error("–ù–∏ –æ–¥–∏–Ω —Ñ–∞–π–ª –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω —É—Å–ø–µ—à–Ω–æ.")
        sys.exit(1)

    merged = (
        pd.concat(all_journals, ignore_index=True)
        .sort_values("–î–∞—Ç–∞")
        .reset_index(drop=True)
    )

    summary = build_monthly_summary(merged)
    large   = build_large_transactions(merged, args.large_threshold)
    manual  = merged[merged["–î–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å"] == "manual"]

    print_console_summary(summary)
    print(f"–í—Å–µ–≥–æ –æ–ø–µ—Ä–∞—Ü–∏–π:       {len(merged)}")
    print(f"–¢—Ä–µ–±—É—é—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏:     {len(manual)}")
    print(f"–ö—Ä—É–ø–Ω—ã–µ (‚â•{args.large_threshold:,.0f} —Ä—É–±.): {len(large)}")

    output_path = Path(args.out)
    export_to_excel(merged, summary, large, output_path)
    print(f"\n‚úÖ –ì–æ—Ç–æ–≤–æ! –û—Ç—á—ë—Ç: {output_path.resolve()}")


if __name__ == "__main__":
    main()
