#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
articles_aggregator.py ‚Äî P&L —Å–≤–æ–¥–∫–∞ –ø–æ –∞—Ä—Ç–∏–∫—É–ª–∞–º –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ WB –¥–µ—Ç–∞–ª—å–Ω—ã—Ö –æ—Ç—á—ë—Ç–æ–≤.

–ß–µ—Ç—ã—Ä–µ —Ä–µ–∂–∏–º–∞ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ (–∞–Ω–∞–ª–æ–≥ P&L –¥–ª—è –æ–±—â–∏—Ö –æ—Ç—á—ë—Ç–æ–≤, –Ω–æ –≤ —Ä–∞–∑—Ä–µ–∑–µ –∞—Ä—Ç–∏–∫—É–ª–æ–≤):
    build_article_summary(df)              ‚Äî all-time —Å–≤–æ–¥–∫–∞, 1 —Å—Ç—Ä–æ–∫–∞ –Ω–∞ –∞—Ä—Ç–∏–∫—É–ª
    build_article_pnl_by_period(df, "M")  ‚Äî –ø–æ –º–µ—Å—è—Ü–∞–º (–∞—Ä—Ç–∏–∫—É–ª √ó –º–µ—Å—è—Ü)
    build_article_pnl_by_period(df, "Q")  ‚Äî –ø–æ –∫–≤–∞—Ä—Ç–∞–ª–∞–º
    build_article_pnl_by_period(df, "Y")  ‚Äî –ø–æ –≥–æ–¥–∞–º
    build_dashboard_rows(df)              ‚Äî –¥–∞—à–±–æ—Ä–¥: –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø–µ—Ä–∏–æ–¥ vs –ø—Ä–µ–¥—ã–¥—É—â–∏–π

–ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö: ¬´–ò—Å—Ç–æ—Ä–∏—è {year}¬ª ‚Äî –≥–æ–¥-–ø–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ª–∏—Å—Ç—ã –¥–µ—Ç–∞–ª—å–Ω—ã—Ö –æ—Ç—á—ë—Ç–æ–≤.
"""

import logging
from datetime import date as _date
from typing import Dict, List, Optional

import pandas as pd

logger = logging.getLogger(__name__)

# ‚îÄ‚îÄ‚îÄ –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

_DOC_TYPE_COL = "–¢–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞"
_SALE_TYPE    = "–ü—Ä–æ–¥–∞–∂–∞"
_RETURN_TYPE  = "–í–æ–∑–≤—Ä–∞—Ç"
_DATE_COL     = "–î–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂–∏"
_ARTICLE_COL  = "–ê—Ä—Ç–∏–∫—É–ª –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞"

# –ö–æ–ª–æ–Ω–∫–∞ –≤—ã–ø–ª–∞—Ç—ã –ø—Ä–æ–¥–∞–≤—Ü—É (–æ—Å–Ω–æ–≤–Ω–∞—è —Ñ–∏–Ω–∞–Ω—Å–æ–≤–∞—è)
_PAYOUT_COL = "–ö –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—é –ü—Ä–æ–¥–∞–≤—Ü—É –∑–∞ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –¢–æ–≤–∞—Ä"

# –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏—è: –ª–æ–≥–∏—á–µ—Å–∫–æ–µ_–∏–º—è ‚Üí –Ω–∞–∑–≤–∞–Ω–∏–µ –≤ —Ñ–∞–π–ª–µ
# –ó–Ω–∞–∫ –±–µ—Ä—ë—Ç—Å—è –∏–∑ –¥–∞–Ω–Ω—ã—Ö –∫–∞–∫ –µ—Å—Ç—å (–∑–∞—Ç—Ä–∞—Ç—ã —Ö—Ä–∞–Ω—è—Ç—Å—è —Å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º –∑–Ω–∞–∫–æ–º).
_FIN_COLS: Dict[str, str] = {
    "commission_gross": "–í–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏–µ —Å –ø—Ä–æ–¥–∞–∂ –¥–æ –≤—ã—á–µ—Ç–∞ —É—Å–ª—É–≥ –ø–æ–≤–µ—Ä–µ–Ω–Ω–æ–≥–æ, –±–µ–∑ –ù–î–°",
    "logistics":        "–£—Å–ª—É–≥–∏ –ø–æ –¥–æ—Å—Ç–∞–≤–∫–µ —Ç–æ–≤–∞—Ä–∞ –ø–æ–∫—É–ø–∞—Ç–µ–ª—é",
    "pvz_service":      "–í–æ–∑–º–µ—â–µ–Ω–∏–µ –∑–∞ –≤—ã–¥–∞—á—É –∏ –≤–æ–∑–≤—Ä–∞—Ç —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ –ü–í–ó",
    "storage":          "–•—Ä–∞–Ω–µ–Ω–∏–µ",
    "holds":            "–£–¥–µ—Ä–∂–∞–Ω–∏—è",
    "acceptance":       "–û–ø–µ—Ä–∞—Ü–∏–∏ –Ω–∞ –ø—Ä–∏–µ–º–∫–µ",
    "logistics_reimb":  "–í–æ–∑–º–µ—â–µ–Ω–∏–µ –∏–∑–¥–µ—Ä–∂–µ–∫ –ø–æ –ø–µ—Ä–µ–≤–æ–∑–∫–µ/–ø–æ —Å–∫–ª–∞–¥—Å–∫–∏–º –æ–ø–µ—Ä–∞—Ü–∏—è–º —Å —Ç–æ–≤–∞—Ä–æ–º",
    "fines":            "–û–±—â–∞—è —Å—É–º–º–∞ —à—Ç—Ä–∞—Ñ–æ–≤",
    "acquiring":        "–≠–∫–≤–∞–π—Ä–∏–Ω–≥/–ö–æ–º–∏—Å—Å–∏–∏ –∑–∞ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—é –ø–ª–∞—Ç–µ–∂–µ–π",
    "loyalty_comp":     "–ö–æ–º–ø–µ–Ω—Å–∞—Ü–∏—è —Å–∫–∏–¥–∫–∏ –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–µ –ª–æ—è–ª—å–Ω–æ—Å—Ç–∏",
}

# –ö–æ–ª–æ–Ω–∫–∏ –∑–∞—Ç—Ä–∞—Ç –∫–æ—Ç–æ—Ä—ã–µ –≤—Ö–æ–¥—è—Ç –≤ —Ä–∞—Å—á—ë—Ç –Ω–µ—Ç—Ç–æ-–ø—Ä–∏–±—ã–ª–∏
# –ù–µ—Ç—Ç–æ = –ö –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—é –ò–¢–û–ì–û + —Å—É–º–º–∞ –≤—Å–µ—Ö –∑–∞—Ç—Ä–∞—Ç–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ (–∑–∞—Ç—Ä–∞—Ç—ã < 0)
_NET_PROFIT_FIN_KEYS = [
    "logistics", "pvz_service", "storage", "holds",
    "acceptance", "logistics_reimb", "fines", "acquiring",
]

# –†—É—Å—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è –º–µ—Å—è—Ü–µ–≤
_MONTH_RU = {
    1: "–Ø–Ω–≤–∞—Ä—å", 2: "–§–µ–≤—Ä–∞–ª—å", 3: "–ú–∞—Ä—Ç", 4: "–ê–ø—Ä–µ–ª—å",
    5: "–ú–∞–π",    6: "–ò—é–Ω—å",    7: "–ò—é–ª—å", 8: "–ê–≤–≥—É—Å—Ç",
    9: "–°–µ–Ω—Ç—è–±—Ä—å", 10: "–û–∫—Ç—è–±—Ä—å", 11: "–ù–æ—è–±—Ä—å", 12: "–î–µ–∫–∞–±—Ä—å",
}

# –ú–µ—Ç–∞-–ø–æ–ª—è: –±–µ—Ä—ë–º –ø–µ—Ä–≤–æ–µ –Ω–µ–ø—É—Å—Ç–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤–Ω—É—Ç—Ä–∏ –≥—Ä—É–ø–ø—ã –∞—Ä—Ç–∏–∫—É–ª–∞
_META_COLS = ["–ù–∞–∑–≤–∞–Ω–∏–µ", "–ü—Ä–µ–¥–º–µ—Ç", "–ë—Ä–µ–Ω–¥"]


# ‚îÄ‚îÄ‚îÄ –ü—É–±–ª–∏—á–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def build_article_summary(history_df: pd.DataFrame) -> pd.DataFrame:
    """
    All-time P&L —Å–≤–æ–¥–∫–∞ –ø–æ –∞—Ä—Ç–∏–∫—É–ª–∞–º (1 —Å—Ç—Ä–æ–∫–∞ = 1 –∞—Ä—Ç–∏–∫—É–ª + —Å—Ç—Ä–æ–∫–∞ –ò–¢–û–ì–û).

    –í–∫–ª—é—á–∞–µ—Ç –ø–æ–ª–Ω—ã–π –Ω–∞–±–æ—Ä —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á—ë—Ç–∞:
    –ø—Ä–æ–¥–∞–∂–∏/–≤–æ–∑–≤—Ä–∞—Ç—ã —à—Ç., % –≤–æ–∑–≤—Ä–∞—Ç–æ–≤, –¥–∞—Ç–∞ –ø–µ—Ä–≤–æ–π/–ø–æ—Å–ª–µ–¥–Ω–µ–π –ø—Ä–æ–¥–∞–∂–∏,
    –ö –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—é (–ø—Ä–æ–¥–∞–∂–∏/–≤–æ–∑–≤—Ä–∞—Ç—ã/–∏—Ç–æ–≥–æ), –≤—Å–µ —Å—Ç–∞—Ç—å–∏ –∑–∞—Ç—Ä–∞—Ç, –Ω–µ—Ç—Ç–æ-–ø—Ä–∏–±—ã–ª—å.

    Args:
        history_df: DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ –∏–∑ ARTICLE_COLUMNS.
                    –ß–∏—Å–ª–æ–≤—ã–µ –ø–æ–ª—è –ø—Ä–∏–≤–æ–¥—è—Ç—Å—è –∫ float –≤–Ω—É—Ç—Ä–∏ —Ñ—É–Ω–∫—Ü–∏–∏
                    (–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏ —Å—Ç—Ä–æ–∫–∏ –∏–∑ Google Sheets, –∏ –Ω–∞—Ç–∏–≤–Ω—ã–µ float).

    Returns:
        DataFrame –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ –ù–µ—Ç—Ç–æ-–ø—Ä–∏–±—ã–ª—å desc + —Å—Ç—Ä–æ–∫–∞ –ò–¢–û–ì–û.
        –ü—É—Å—Ç–æ–π DataFrame –µ—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –Ω–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ ¬´–ê—Ä—Ç–∏–∫—É–ª –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞¬ª.

    Side effects:
        –ù–µ—Ç ‚Äî —Ç–æ–ª—å–∫–æ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ.

    Invariants:
        - history_df –Ω–µ –º—É—Ç–∏—Ä—É–µ—Ç—Å—è.
        - –ü—Ä–∏ –ø—É—Å—Ç–æ–º df ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Å—Ç–æ–π DataFrame.
    """
    if history_df.empty or _ARTICLE_COL not in history_df.columns:
        return pd.DataFrame()

    df = _prep_df(history_df)

    rows = []
    for article, grp in df.groupby(_ARTICLE_COL, sort=True):
        metrics = _article_metrics(grp)

        # –ü–µ—Ä–∏–æ–¥ –ø–æ –∞—Ä—Ç–∏–∫—É–ª—É (–ø–µ—Ä–≤–∞—è –∏ –ø–æ—Å–ª–µ–¥–Ω—è—è –¥–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂–∏)
        if "_sale_date" in grp.columns:
            valid_dates = grp["_sale_date"].dropna()
            date_first = valid_dates.min().strftime("%d.%m.%Y") if not valid_dates.empty else ""
            date_last  = valid_dates.max().strftime("%d.%m.%Y") if not valid_dates.empty else ""
        else:
            date_first = date_last = ""

        row: Dict = {
            _ARTICLE_COL:              str(article),
            "–ù–∞–∑–≤–∞–Ω–∏–µ":                _first_nonempty(grp, "–ù–∞–∑–≤–∞–Ω–∏–µ"),
            "–ü—Ä–µ–¥–º–µ—Ç":                 _first_nonempty(grp, "–ü—Ä–µ–¥–º–µ—Ç"),
            "–ë—Ä–µ–Ω–¥":                   _first_nonempty(grp, "–ë—Ä–µ–Ω–¥"),
            "–ü–µ—Ä–≤–∞—è –ø—Ä–æ–¥–∞–∂–∞":          date_first,
            "–ü–æ—Å–ª–µ–¥–Ω—è—è –ø—Ä–æ–¥–∞–∂–∞":       date_last,
            **metrics,
        }
        rows.append(row)

    if not rows:
        return pd.DataFrame()

    result = pd.DataFrame(rows)

    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –Ω–µ—Ç—Ç–æ-–ø—Ä–∏–±—ã–ª–∏ (–ª—É—á—à–∏–µ –∞—Ä—Ç–∏–∫—É–ª—ã –Ω–∞–≤–µ—Ä—Ö—É)
    result = result.sort_values("–ù–µ—Ç—Ç–æ-–ø—Ä–∏–±—ã–ª—å", ascending=False).reset_index(drop=True)

    # –°—Ç—Ä–æ–∫–∞ –ò–¢–û–ì–û
    totals: Dict = {
        _ARTICLE_COL:              "–ò–¢–û–ì–û",
        "–ù–∞–∑–≤–∞–Ω–∏–µ":                "",
        "–ü—Ä–µ–¥–º–µ—Ç":                 "",
        "–ë—Ä–µ–Ω–¥":                   "",
        "–ü–µ—Ä–≤–∞—è –ø—Ä–æ–¥–∞–∂–∞":          result["–ü–µ—Ä–≤–∞—è –ø—Ä–æ–¥–∞–∂–∞"].min() if not result.empty else "",
        "–ü–æ—Å–ª–µ–¥–Ω—è—è –ø—Ä–æ–¥–∞–∂–∞":       result["–ü–æ—Å–ª–µ–¥–Ω—è—è –ø—Ä–æ–¥–∞–∂–∞"].max() if not result.empty else "",
        "–ü—Ä–æ–¥–∞–∂–∏ (—à—Ç.)":           int(result["–ü—Ä–æ–¥–∞–∂–∏ (—à—Ç.)"].sum()),
        "–í–æ–∑–≤—Ä–∞—Ç—ã (—à—Ç.)":          int(result["–í–æ–∑–≤—Ä–∞—Ç—ã (—à—Ç.)"].sum()),
        "% –≤–æ–∑–≤—Ä–∞—Ç–æ–≤":             _total_return_rate(result),
        "–ö –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—é (–ü—Ä–æ–¥–∞–∂–∏)":  round(float(result["–ö –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—é (–ü—Ä–æ–¥–∞–∂–∏)"].sum()), 2),
        "–ö –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—é (–í–æ–∑–≤—Ä–∞—Ç—ã)": round(float(result["–ö –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—é (–í–æ–∑–≤—Ä–∞—Ç—ã)"].sum()), 2),
        "–ö –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—é –ò–¢–û–ì–û":      round(float(result["–ö –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—é –ò–¢–û–ì–û"].sum()), 2),
        "–ù–µ—Ç—Ç–æ-–ø—Ä–∏–±—ã–ª—å":             round(float(result["–ù–µ—Ç—Ç–æ-–ø—Ä–∏–±—ã–ª—å"].sum()), 2),
        "–õ–æ–≥–∏—Å—Ç–∏–∫–∞ –Ω–∞ –µ–¥.":          "",
    }
    for fin_key, col_name in _FIN_COLS.items():
        col_label = _fin_col_label(fin_key)
        if col_label in result.columns:
            totals[col_label] = round(float(result[col_label].sum()), 2)

    logger.info(
        "build_article_summary: %d –∞—Ä—Ç–∏–∫—É–ª–æ–≤, –ø—Ä–æ–¥–∞–∂–∏=%d, –≤–æ–∑–≤—Ä–∞—Ç—ã=%d",
        len(result),
        totals["–ü—Ä–æ–¥–∞–∂–∏ (—à—Ç.)"],
        totals["–í–æ–∑–≤—Ä–∞—Ç—ã (—à—Ç.)"],
    )

    return pd.concat([result, pd.DataFrame([totals])], ignore_index=True)


def build_article_pnl_by_period(
    history_df: pd.DataFrame,
    freq: str = "M",
) -> pd.DataFrame:
    """
    P&L –ø–æ –∞—Ä—Ç–∏–∫—É–ª–∞–º –≤ —Ä–∞–∑—Ä–µ–∑–µ –ø–µ—Ä–∏–æ–¥–∞ (–∞–Ω–∞–ª–æ–≥ pnl_by_period –¥–ª—è –æ–±—â–µ–≥–æ –æ—Ç—á—ë—Ç–∞).

    Args:
        history_df: DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ –∏–∑ ARTICLE_COLUMNS.
        freq: –ß–∞—Å—Ç–æ—Ç–∞ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ ‚Äî "M" (–º–µ—Å—è—Ü), "Q" (–∫–≤–∞—Ä—Ç–∞–ª), "Y" (–≥–æ–¥).

    Returns:
        DataFrame: –ì–æ–¥ | –ü–µ—Ä–∏–æ–¥ | –ê—Ä—Ç–∏–∫—É–ª | –ù–∞–∑–≤–∞–Ω–∏–µ | –ë—Ä–µ–Ω–¥ | –ü—Ä–µ–¥–º–µ—Ç
                   | –ü—Ä–æ–¥–∞–∂–∏ —à—Ç. | –í–æ–∑–≤—Ä–∞—Ç—ã —à—Ç. | % –≤–æ–∑–≤—Ä–∞—Ç–æ–≤
                   | –ö –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—é (–ü—Ä–æ–¥–∞–∂–∏/–í–æ–∑–≤—Ä–∞—Ç—ã/–ò–¢–û–ì–û)
                   | –ö–æ–º–∏—Å—Å–∏—è –í–í | –õ–æ–≥–∏—Å—Ç–∏–∫–∞ | –£—Å–ª—É–≥–∏ –ü–í–ó | –•—Ä–∞–Ω–µ–Ω–∏–µ
                   | –£–¥–µ—Ä–∂–∞–Ω–∏—è | –ü—Ä–∏—ë–º–∫–∞ | –í–æ–∑–º–µ—â–µ–Ω–∏–µ –ª–æ–≥–∏—Å—Ç–∏–∫–∏ | –®—Ç—Ä–∞—Ñ—ã
                   | –≠–∫–≤–∞–π—Ä–∏–Ω–≥ | –ö–æ–º–ø–µ–Ω—Å–∞—Ü–∏—è –ª–æ—è–ª—å–Ω–æ—Å—Ç–∏
                   | –ù–µ—Ç—Ç–æ-–ø—Ä–∏–±—ã–ª—å | –õ–æ–≥–∏—Å—Ç–∏–∫–∞ –Ω–∞ –µ–¥.

        –°—Ç—Ä–æ–∫–∏ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã: –≥–æ–¥‚Üì, –º–µ—Å—è—Ü‚Üì, –Ω–µ—Ç—Ç–æ-–ø—Ä–∏–±—ã–ª—å‚Üì (–Ω–æ–≤–µ–π—à–∏–µ –ø–µ—Ä–∏–æ–¥—ã —Å–≤–µ—Ä—Ö—É).
        –ü—É—Å—Ç–æ–π DataFrame –µ—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –Ω–µ—Ç ¬´–î–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂–∏¬ª.

    Side effects:
        –ù–µ—Ç ‚Äî —Ç–æ–ª—å–∫–æ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ.

    Invariants:
        - history_df –Ω–µ –º—É—Ç–∏—Ä—É–µ—Ç—Å—è.
        - –°—Ç—Ä–æ–∫–∏ –±–µ–∑ ¬´–î–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂–∏¬ª (NaT) –∏—Å–∫–ª—é—á–∞—é—Ç—Å—è –∏–∑ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –ø–æ –ø–µ—Ä–∏–æ–¥—É.
    """
    if history_df.empty or _ARTICLE_COL not in history_df.columns:
        return pd.DataFrame()

    df = _prep_df(history_df)

    # –¢–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏ —Å –≤–∞–ª–∏–¥–Ω–æ–π –¥–∞—Ç–æ–π –ø—Ä–æ–¥–∞–∂–∏
    df = df.dropna(subset=["_sale_date"]).copy()
    if df.empty:
        return pd.DataFrame()

    df["_period"] = df["_sale_date"].dt.to_period(freq)

    rows = []
    for (period, article), grp in df.groupby(["_period", _ARTICLE_COL], sort=True):
        metrics = _article_metrics(grp)
        ts = period.start_time

        row: Dict = {
            "–ì–æ–¥":      int(ts.year),
            "–ü–µ—Ä–∏–æ–¥":   _period_label(ts, freq),
            "_ord":     period.ordinal,
            _ARTICLE_COL:  str(article),
            "–ù–∞–∑–≤–∞–Ω–∏–µ":    _first_nonempty(grp, "–ù–∞–∑–≤–∞–Ω–∏–µ"),
            "–ë—Ä–µ–Ω–¥":       _first_nonempty(grp, "–ë—Ä–µ–Ω–¥"),
            "–ü—Ä–µ–¥–º–µ—Ç":     _first_nonempty(grp, "–ü—Ä–µ–¥–º–µ—Ç"),
            **metrics,
        }
        rows.append(row)

    if not rows:
        return pd.DataFrame()

    result = pd.DataFrame(rows)

    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞: –Ω–æ–≤—ã–µ –ø–µ—Ä–∏–æ–¥—ã —Å–≤–µ—Ä—Ö—É, –≤–Ω—É—Ç—Ä–∏ –ø–µ—Ä–∏–æ–¥–∞ ‚Äî –ø–æ –Ω–µ—Ç—Ç–æ-–ø—Ä–∏–±—ã–ª–∏ desc
    result = (
        result
        .sort_values(["_ord", "–ù–µ—Ç—Ç–æ-–ø—Ä–∏–±—ã–ª—å"], ascending=[False, False])
        .drop(columns=["_ord"])
        .reset_index(drop=True)
    )

    logger.info(
        "build_article_pnl_by_period(freq=%s): %d —Å—Ç—Ä–æ–∫ (%d —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∞—Ä—Ç–∏–∫—É–ª–æ–≤)",
        freq,
        len(result),
        result[_ARTICLE_COL].nunique(),
    )
    return result


def build_dashboard_rows(history_df: pd.DataFrame) -> List[List]:
    """
    –î–∞—à–±–æ—Ä–¥: –ø–æ—Å–ª–µ–¥–Ω–∏–π –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π –º–µ—Å—è—Ü vs –ø—Ä–µ–¥—ã–¥—É—â–∏–π.

    –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –≤—ã–≤–æ–¥–∞ (—Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ –¥–ª—è Google Sheets):
        –°—Ç—Ä–æ–∫–∞ 1:  –∑–∞–≥–æ–ª–æ–≤–æ–∫ (–ø–µ—Ä–∏–æ–¥, –¥–∞—Ç–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è)
        –°—Ç—Ä–æ–∫–∞ 2:  –ø—É—Å—Ç–∞—è
        –°—Ç—Ä–æ–∫–∞ 3:  ¬´–°–í–û–î–ù–´–ï –ò–¢–û–ì–ò¬ª
        –°—Ç—Ä–æ–∫–∏ 4+: –º–µ—Ç—Ä–∏–∫–∞ | —Ç–µ–∫—É—â–∏–π –ø–µ—Ä–∏–æ–¥ | –ø—Ä–µ–¥—ã–¥—É—â–∏–π –ø–µ—Ä–∏–æ–¥ | Œî (–∞–±—Å.) | Œî (%)
        –ü—É—Å—Ç–∞—è
        ¬´–î–ï–¢–ê–õ–ò–ó–ê–¶–ò–Ø –ü–û –ê–†–¢–ò–ö–£–õ–ê–ú ‚Äî {cur_label}¬ª
        –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Ç–∞–±–ª–∏—Ü—ã –∞—Ä—Ç–∏–∫—É–ª–æ–≤
        –°—Ç—Ä–æ–∫–∏ –∞—Ä—Ç–∏–∫—É–ª–æ–≤ (–æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –ø–æ –Ω–µ—Ç—Ç–æ-–ø—Ä–∏–±—ã–ª–∏ desc) + Œî –ù–µ—Ç—Ç–æ-–ø—Ä–∏–±—ã–ª—å, Œî%

    Args:
        history_df: –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π DataFrame –∏–∑ –≤—Å–µ—Ö –ò—Å—Ç–æ—Ä–∏—è {year} –ª–∏—Å—Ç–æ–≤.

    Returns:
        list[list] ‚Äî –≥–æ—Ç–æ–≤–æ –¥–ª—è ws.update("A1", rows).
        –ü—Ä–∏ –ø—É—Å—Ç—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç [["–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"]].

    Side effects:
        –ù–µ—Ç ‚Äî —Ç–æ–ª—å–∫–æ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ.

    Invariants:
        - history_df –Ω–µ –º—É—Ç–∏—Ä—É–µ—Ç—Å—è.
        - –ü–µ—Ä–∏–æ–¥ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –ø–æ ¬´–î–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂–∏¬ª (–º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –º–µ—Å—è—Ü).
    """
    if history_df.empty or _ARTICLE_COL not in history_df.columns:
        return [["–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"]]

    df = _prep_df(history_df)
    df_valid = df.dropna(subset=["_sale_date"]).copy()

    if df_valid.empty:
        return [["–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"]]

    df_valid["_period"] = df_valid["_sale_date"].dt.to_period("M")
    periods = sorted(df_valid["_period"].unique())

    cur_period  = periods[-1]
    prev_period = periods[-2] if len(periods) >= 2 else None

    cur_label  = _period_label(cur_period.start_time, "M")
    prev_label = _period_label(prev_period.start_time, "M") if prev_period else None

    cur_df  = df_valid[df_valid["_period"] == cur_period]
    prev_df = df_valid[df_valid["_period"] == prev_period] if prev_period else pd.DataFrame()

    # ‚îÄ‚îÄ Summary metrics ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    _SUMMARY_KEYS = [
        ("–ü—Ä–æ–¥–∞–∂–∏ (—à—Ç.)",               "–ü—Ä–æ–¥–∞–∂–∏ (—à—Ç.)"),
        ("–í–æ–∑–≤—Ä–∞—Ç—ã (—à—Ç.)",              "–í–æ–∑–≤—Ä–∞—Ç—ã (—à—Ç.)"),
        ("% –≤–æ–∑–≤—Ä–∞—Ç–æ–≤",                 "% –≤–æ–∑–≤—Ä–∞—Ç–æ–≤"),
        ("–ö –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—é (–ü—Ä–æ–¥–∞–∂–∏)",    "–ö –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—é (–ü—Ä–æ–¥–∞–∂–∏)"),
        ("–ö –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—é (–í–æ–∑–≤—Ä–∞—Ç—ã)",   "–ö –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—é (–í–æ–∑–≤—Ä–∞—Ç—ã)"),
        ("–ö –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—é –ò–¢–û–ì–û",        "–ö –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—é –ò–¢–û–ì–û"),
        ("–ö–æ–º–∏—Å—Å–∏—è –í–í",                 _fin_col_label("commission_gross")),
        ("–õ–æ–≥–∏—Å—Ç–∏–∫–∞",                   _fin_col_label("logistics")),
        ("–£—Å–ª—É–≥–∏ –ü–í–ó",                  _fin_col_label("pvz_service")),
        ("–•—Ä–∞–Ω–µ–Ω–∏–µ",                    _fin_col_label("storage")),
        ("–£–¥–µ—Ä–∂–∞–Ω–∏—è",                   _fin_col_label("holds")),
        ("–®—Ç—Ä–∞—Ñ—ã",                      _fin_col_label("fines")),
        ("–ù–µ—Ç—Ç–æ-–ø—Ä–∏–±—ã–ª—å",               "–ù–µ—Ç—Ç–æ-–ø—Ä–∏–±—ã–ª—å"),
    ]

    cur_tot  = _article_metrics(cur_df)
    prev_tot = _article_metrics(prev_df) if not prev_df.empty else {}

    rows: List[List] = []

    upd_str = _date.today().strftime("%d.%m.%Y")
    rows.append([
        "üìä –î–∞—à–±–æ—Ä–¥ WB ‚Äî –ê—Ä—Ç–∏–∫—É–ª—ã", "",
        f"–¢–µ–∫—É—â–∏–π –ø–µ—Ä–∏–æ–¥: {cur_label}", "",
        f"–ü—Ä–µ–¥—ã–¥—É—â–∏–π: {prev_label or '‚Äî'}", "",
        f"–û–±–Ω–æ–≤–ª–µ–Ω–æ: {upd_str}",
    ])
    rows.append([])
    rows.append(["–°–í–û–î–ù–´–ï –ò–¢–û–ì–ò"])

    cmp_cols = [prev_label or "–ü—Ä–µ–¥—ã–¥—É—â–∏–π –ø–µ—Ä–∏–æ–¥", "Œî (–∞–±—Å.)", "Œî (%)"] if prev_label else []
    rows.append(["–ú–µ—Ç—Ä–∏–∫–∞", cur_label] + cmp_cols)

    for label, key in _SUMMARY_KEYS:
        cur_v = cur_tot.get(key, 0)
        row: List = [label, cur_v]
        if prev_label:
            prev_v = prev_tot.get(key, 0)
            row += _delta_cells(cur_v, prev_v)
        rows.append(row)

    # ‚îÄ‚îÄ Article detail ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    rows.append([])
    rows.append([f"–î–ï–¢–ê–õ–ò–ó–ê–¶–ò–Ø –ü–û –ê–†–¢–ò–ö–£–õ–ê–ú ‚Äî {cur_label}"])

    art_base_header = [
        _ARTICLE_COL, "–ù–∞–∑–≤–∞–Ω–∏–µ", "–ë—Ä–µ–Ω–¥", "–ü—Ä–µ–¥–º–µ—Ç",
        "–ü—Ä–æ–¥–∞–∂–∏ (—à—Ç.)", "–í–æ–∑–≤—Ä–∞—Ç—ã (—à—Ç.)", "% –≤–æ–∑–≤—Ä–∞—Ç–æ–≤",
        "–ö –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—é (–ü—Ä–æ–¥–∞–∂–∏)", "–ö –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—é (–í–æ–∑–≤—Ä–∞—Ç—ã)", "–ö –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—é –ò–¢–û–ì–û",
        _fin_col_label("commission_gross"), _fin_col_label("logistics"),
        _fin_col_label("pvz_service"), _fin_col_label("storage"),
        _fin_col_label("holds"), _fin_col_label("acceptance"),
        _fin_col_label("logistics_reimb"), _fin_col_label("fines"),
        _fin_col_label("acquiring"), _fin_col_label("loyalty_comp"),
        "–ù–µ—Ç—Ç–æ-–ø—Ä–∏–±—ã–ª—å", "–õ–æ–≥–∏—Å—Ç–∏–∫–∞ –Ω–∞ –µ–¥.",
    ]
    delta_header = ["Œî –ù–µ—Ç—Ç–æ-–ø—Ä–∏–±—ã–ª—å", "Œî% –ù–µ—Ç—Ç–æ-–ø—Ä–∏–±—ã–ª—å"] if prev_label else []
    rows.append(art_base_header + delta_header)

    # Previous period metrics by article
    prev_art: Dict[str, Dict] = {}
    if not prev_df.empty:
        for article, grp in prev_df.groupby(_ARTICLE_COL):
            prev_art[str(article)] = _article_metrics(grp)

    # Current period article rows
    art_rows = []
    for article, grp in cur_df.groupby(_ARTICLE_COL, sort=True):
        m = _article_metrics(grp)
        art_str = str(article)
        row = [
            art_str,
            _first_nonempty(grp, "–ù–∞–∑–≤–∞–Ω–∏–µ"),
            _first_nonempty(grp, "–ë—Ä–µ–Ω–¥"),
            _first_nonempty(grp, "–ü—Ä–µ–¥–º–µ—Ç"),
            m["–ü—Ä–æ–¥–∞–∂–∏ (—à—Ç.)"],
            m["–í–æ–∑–≤—Ä–∞—Ç—ã (—à—Ç.)"],
            m["% –≤–æ–∑–≤—Ä–∞—Ç–æ–≤"],
            m["–ö –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—é (–ü—Ä–æ–¥–∞–∂–∏)"],
            m["–ö –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—é (–í–æ–∑–≤—Ä–∞—Ç—ã)"],
            m["–ö –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—é –ò–¢–û–ì–û"],
            m.get(_fin_col_label("commission_gross"), 0),
            m.get(_fin_col_label("logistics"), 0),
            m.get(_fin_col_label("pvz_service"), 0),
            m.get(_fin_col_label("storage"), 0),
            m.get(_fin_col_label("holds"), 0),
            m.get(_fin_col_label("acceptance"), 0),
            m.get(_fin_col_label("logistics_reimb"), 0),
            m.get(_fin_col_label("fines"), 0),
            m.get(_fin_col_label("acquiring"), 0),
            m.get(_fin_col_label("loyalty_comp"), 0),
            m["–ù–µ—Ç—Ç–æ-–ø—Ä–∏–±—ã–ª—å"],
            m["–õ–æ–≥–∏—Å—Ç–∏–∫–∞ –Ω–∞ –µ–¥."],
        ]
        if prev_label:
            pm = prev_art.get(art_str, {})
            row += _delta_cells(m["–ù–µ—Ç—Ç–æ-–ø—Ä–∏–±—ã–ª—å"], pm.get("–ù–µ—Ç—Ç–æ-–ø—Ä–∏–±—ã–ª—å", 0))
        art_rows.append((float(m["–ù–µ—Ç—Ç–æ-–ø—Ä–∏–±—ã–ª—å"]), row))

    art_rows.sort(key=lambda x: -x[0])
    rows.extend(r for _, r in art_rows)

    logger.info(
        "build_dashboard_rows: –ø–µ—Ä–∏–æ–¥=%s, –∞—Ä—Ç–∏–∫—É–ª–æ–≤=%d, —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ=%s",
        cur_label, len(art_rows), prev_label or "–Ω–µ—Ç",
    )
    return rows


# ‚îÄ‚îÄ‚îÄ –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def _prep_df(history_df: pd.DataFrame) -> pd.DataFrame:
    """–ü—Ä–∏–≤–µ—Å—Ç–∏ —á–∏—Å–ª–æ–≤—ã–µ –∏ –¥–∞—Ç–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –∫ –Ω—É–∂–Ω—ã–º —Ç–∏–ø–∞–º (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è –æ—Ä–∏–≥–∏–Ω–∞–ª–∞)."""
    df = history_df.copy()

    # –ß–∏—Å–ª–æ–≤—ã–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ (—Å—Ç—Ä–æ–∫–∏ –∏–∑ Sheets ‚Üí float)
    for col in [_PAYOUT_COL] + list(_FIN_COLS.values()):
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0.0)

    # –î–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂–∏ ‚Üí datetime
    if _DATE_COL in df.columns:
        df["_sale_date"] = pd.to_datetime(df[_DATE_COL], errors="coerce")
    else:
        df["_sale_date"] = pd.NaT

    return df


def _article_metrics(grp: pd.DataFrame) -> Dict:
    """–í—ã—á–∏—Å–ª–∏—Ç—å –≤—Å–µ P&L –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –≥—Ä—É–ø–ø—ã —Å—Ç—Ä–æ–∫ –æ–¥–Ω–æ–≥–æ –∞—Ä—Ç–∏–∫—É–ª–∞ (–∏–ª–∏ –∞—Ä—Ç–∏–∫—É–ª√ó–ø–µ—Ä–∏–æ–¥)."""
    has_doc_type = _DOC_TYPE_COL in grp.columns

    if has_doc_type:
        sales_grp   = grp[grp[_DOC_TYPE_COL] == _SALE_TYPE]
        returns_grp = grp[grp[_DOC_TYPE_COL] == _RETURN_TYPE]
    else:
        sales_grp   = grp
        returns_grp = pd.DataFrame(columns=grp.columns)

    n_sales   = len(sales_grp)
    n_returns = len(returns_grp)
    total     = n_sales + n_returns
    return_rate = round(n_returns / total * 100, 1) if total > 0 else 0.0

    # –í—ã–ø–ª–∞—Ç—ã –ø—Ä–æ–¥–∞–≤—Ü—É
    payout_sales   = _fsum(sales_grp,   _PAYOUT_COL)
    payout_returns = _fsum(returns_grp, _PAYOUT_COL)
    payout_total   = _fsum(grp,         _PAYOUT_COL)

    # –í—Å–µ –ø—Ä–æ—á–∏–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏
    fin_sums: Dict[str, float] = {
        key: _fsum(grp, col)
        for key, col in _FIN_COLS.items()
    }

    # –ù–µ—Ç—Ç–æ-–ø—Ä–∏–±—ã–ª—å = –ö –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—é –ò–¢–û–ì–û + –≤—Å–µ –∑–∞—Ç—Ä–∞—Ç—ã (–∑–∞—Ç—Ä–∞—Ç—ã < 0 ‚Üí —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ)
    net_profit = round(
        payout_total + sum(fin_sums[k] for k in _NET_PROFIT_FIN_KEYS),
        2,
    )

    logistics_per_unit = round(fin_sums["logistics"] / n_sales, 2) if n_sales > 0 else 0.0

    return {
        "–ü—Ä–æ–¥–∞–∂–∏ (—à—Ç.)":              n_sales,
        "–í–æ–∑–≤—Ä–∞—Ç—ã (—à—Ç.)":             n_returns,
        "% –≤–æ–∑–≤—Ä–∞—Ç–æ–≤":                return_rate,
        "–ö –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—é (–ü—Ä–æ–¥–∞–∂–∏)":   payout_sales,
        "–ö –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—é (–í–æ–∑–≤—Ä–∞—Ç—ã)":  payout_returns,
        "–ö –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—é –ò–¢–û–ì–û":       payout_total,
        # –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ —Å —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã–º–∏ –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏
        _fin_col_label("commission_gross"): fin_sums["commission_gross"],
        _fin_col_label("logistics"):        fin_sums["logistics"],
        _fin_col_label("pvz_service"):      fin_sums["pvz_service"],
        _fin_col_label("storage"):          fin_sums["storage"],
        _fin_col_label("holds"):            fin_sums["holds"],
        _fin_col_label("acceptance"):       fin_sums["acceptance"],
        _fin_col_label("logistics_reimb"):  fin_sums["logistics_reimb"],
        _fin_col_label("fines"):            fin_sums["fines"],
        _fin_col_label("acquiring"):        fin_sums["acquiring"],
        _fin_col_label("loyalty_comp"):     fin_sums["loyalty_comp"],
        "–ù–µ—Ç—Ç–æ-–ø—Ä–∏–±—ã–ª—å":                    net_profit,
        "–õ–æ–≥–∏—Å—Ç–∏–∫–∞ –Ω–∞ –µ–¥.":                 logistics_per_unit,
    }


def _fin_col_label(key: str) -> str:
    """–ß–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ –∫–ª—é—á–∞ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ –∑–∞–≥–æ–ª–æ–≤–∫–∞—Ö Sheets)."""
    _LABELS = {
        "commission_gross": "–ö–æ–º–∏—Å—Å–∏—è –í–í",
        "logistics":        "–õ–æ–≥–∏—Å—Ç–∏–∫–∞",
        "pvz_service":      "–£—Å–ª—É–≥–∏ –ü–í–ó",
        "storage":          "–•—Ä–∞–Ω–µ–Ω–∏–µ",
        "holds":            "–£–¥–µ—Ä–∂–∞–Ω–∏—è",
        "acceptance":       "–û–ø–µ—Ä–∞—Ü–∏–∏ –Ω–∞ –ø—Ä–∏–µ–º–∫–µ",
        "logistics_reimb":  "–í–æ–∑–º–µ—â–µ–Ω–∏–µ –ª–æ–≥–∏—Å—Ç–∏–∫–∏",
        "fines":            "–®—Ç—Ä–∞—Ñ—ã",
        "acquiring":        "–≠–∫–≤–∞–π—Ä–∏–Ω–≥",
        "loyalty_comp":     "–ö–æ–º–ø–µ–Ω—Å–∞—Ü–∏—è –ª–æ—è–ª—å–Ω–æ—Å—Ç–∏",
    }
    return _LABELS.get(key, key)


def _fsum(frame: pd.DataFrame, col: Optional[str]) -> float:
    """–°—É–º–º–∞ —á–∏—Å–ª–æ–≤–æ–π –∫–æ–ª–æ–Ω–∫–∏ (0.0 –µ—Å–ª–∏ –∫–æ–ª–æ–Ω–∫–∏ –Ω–µ—Ç –∏–ª–∏ frame –ø—É—Å—Ç–æ–π)."""
    if col is None or frame.empty or col not in frame.columns:
        return 0.0
    return round(float(frame[col].fillna(0.0).sum()), 2)


def _period_label(ts: "pd.Timestamp", freq: str) -> str:
    """–ß–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º–∞—è –º–µ—Ç–∫–∞ –ø–µ—Ä–∏–æ–¥–∞ –∏–∑ timestamp."""
    if freq == "M":
        return f"{_MONTH_RU[ts.month]} {ts.year}"
    elif freq == "Q":
        quarter = (ts.month - 1) // 3 + 1
        return f"Q{quarter} {ts.year}"
    else:  # "Y"
        return str(ts.year)


def _total_return_rate(result: pd.DataFrame) -> float:
    """–û–±—â–∏–π % –≤–æ–∑–≤—Ä–∞—Ç–æ–≤ –¥–ª—è —Å—Ç—Ä–æ–∫–∏ –ò–¢–û–ì–û."""
    n_sales   = result["–ü—Ä–æ–¥–∞–∂–∏ (—à—Ç.)"].sum()
    n_returns = result["–í–æ–∑–≤—Ä–∞—Ç—ã (—à—Ç.)"].sum()
    total = n_sales + n_returns
    return round(n_returns / total * 100, 1) if total > 0 else 0.0


def _delta_cells(cur_v, prev_v) -> list:
    """–í–µ—Ä–Ω—É—Ç—å [prev_v, delta_abs, delta_pct] –¥–ª—è —è—á–µ–µ–∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ø–µ—Ä–∏–æ–¥–æ–≤."""
    try:
        c = float(cur_v)
        p = float(prev_v)
    except (TypeError, ValueError):
        return [prev_v, "", ""]
    delta = round(c - p, 2)
    if p != 0:
        delta_pct = f"{delta / abs(p) * 100:+.1f}%"
    elif delta > 0:
        delta_pct = "+‚àû"
    elif delta < 0:
        delta_pct = "-‚àû"
    else:
        delta_pct = "0.0%"
    return [p, delta, delta_pct]


def _first_nonempty(grp: pd.DataFrame, col: str) -> str:
    """–í–µ—Ä–Ω—É—Ç—å –ø–µ—Ä–≤–æ–µ –Ω–µ–ø—É—Å—Ç–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏, –∏–Ω–∞—á–µ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É."""
    if col not in grp.columns:
        return ""
    vals = grp[col].dropna().astype(str)
    vals = vals[vals.str.strip() != ""]
    return vals.iloc[0] if not vals.empty else ""
