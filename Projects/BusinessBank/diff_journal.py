#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–°–≤–µ—Ä–∫–∞ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–≥–æ –∂—É—Ä–Ω–∞–ª–∞ –æ–ø–µ—Ä–∞—Ü–∏–π —Å –±–∞–Ω–∫–æ–≤—Å–∫–æ–π –≤—ã–ø–∏—Å–∫–æ–π.

–õ–æ–≥–∏–∫–∞:
  - –ë–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ: —Å –ø–µ—Ä–≤–æ–π –¥–∞—Ç—ã –≤ –∂—É—Ä–Ω–∞–ª–µ
  - –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º –ø–æ (–¥–∞—Ç–∞, —Å—É–º–º–∞ ¬± 1 —Ä—É–±) –≤ –∫–æ–ª–æ–Ω–∫–µ –ú–æ–¥—É–ª—å–ë–∞–Ω–∫ —Ä/—Å
  - –í—ã–≤–æ–¥–∏–º: —á—Ç–æ —Å–æ–≤–ø–∞–ª–æ / —á–µ–≥–æ –Ω–µ—Ç –≤ –∂—É—Ä–Ω–∞–ª–µ / —á—Ç–æ —Ç–æ–ª—å–∫–æ –≤ –∂—É—Ä–Ω–∞–ª–µ

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python -X utf8 diff_journal.py \
        --bank "–ü—Ä–∏–º–µ—Ä—ã –≤—ã–ø–∏—Å–æ–∫ –∏–∑ –ú–æ–¥—É–ª—å–±–∞–Ω–∫–∞/Statement ...xlsx" \
        --journal "../../–§–∏–Ω–∞–Ω—Å–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞/–ñ—É—Ä–Ω–∞–ª –æ–ø–µ—Ä–∞—Ü–∏–π –î–ë–ó .xlsx" \
        --entity DBZ \
        --owner "–ü–∏—Ä–æ–∂–∫–æ–≤–∞ –ù–∞—Ç–∞–ª—å—è –í–∏–∫—Ç–æ—Ä–æ–≤–Ω–∞" \
        --out diff_DBZ.xlsx
"""

import argparse
import io
import logging
import sys
from datetime import date
from pathlib import Path

import pandas as pd

if sys.stdout.encoding != "utf-8":
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding="utf-8", errors="replace")
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding="utf-8", errors="replace")

sys.path.insert(0, str(Path(__file__).parent))

from src.classifier import TransactionClassifier
from src.parser import parse_statement

logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

TOLERANCE = 1.0  # —Ä—É–±–ª–µ–π ‚Äî –¥–æ–ø—É—Å–∫ –ø—Ä–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–∏ —Å—É–º–º


# ‚îÄ‚îÄ 1. –ß–¢–ï–ù–ò–ï –ñ–£–†–ù–ê–õ–ê ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def read_journal_modulbank(journal_path: Path) -> pd.DataFrame:
    """
    –ß–∏—Ç–∞–µ—Ç –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–π –∂—É—Ä–Ω–∞–ª (—ç–∫—Å–ø–æ—Ä—Ç Google Sheets).
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–π DataFrame —Ç–æ–ª—å–∫–æ –¥–ª—è –∫–æ–ª–æ–Ω–∫–∏ –ú–æ–¥—É–ª—å–ë–∞–Ω–∫ —Ä/—Å:
        date (date) | amount (float, + –ø—Ä–∏—Ö–æ–¥ / ‚àí —Ä–∞—Å—Ö–æ–¥) | comment (str)

    –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∞–π–ª–∞:
        –°—Ç—Ä–æ–∫–∞ 0 ‚Äî —Å–≤–æ–¥–∫–∞ —Ç–µ–∫—É—â–∏—Ö –æ—Å—Ç–∞—Ç–∫–æ–≤ (–ø—Ä–æ–ø—É—Å–∫–∞–µ–º)
        –°—Ç—Ä–æ–∫–∞ 1 ‚Äî –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∫–æ–ª–æ–Ω–æ–∫  ‚Üê header
        –°—Ç—Ä–æ–∫–∞ 2 ‚Äî —Å—Ç—Ä–æ–∫–∞ –æ—Ç–∫—Ä—ã—Ç–∏—è (–¢–µ–∫—É—â–∏–π –±–∞–ª–∞–Ω—Å –Ω–∞ ...)
        –°—Ç—Ä–æ–∫–∏ 3+ ‚Äî —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
    """
    df_raw = pd.read_excel(journal_path, header=1)  # —Å—Ç—Ä–æ–∫–∞ 1 = –∑–∞–≥–æ–ª–æ–≤–æ–∫

    # –ò—â–µ–º –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –ø–æ –∏–º–µ–Ω–∏ (—Å fallback –Ω–∞ –ø–æ–∑–∏—Ü–∏—é)
    date_col = _find_col(df_raw, ["–¥–∞—Ç–∞", "date"], fallback=0)
    mb_col   = _find_col(df_raw, ["–º–æ–¥—É–ª—å–±–∞–Ω–∫ —Ä/—Å", "–º–æ–¥—É–ª—å–±–∞–Ω–∫ —Ä/—Å", "—Ä/—Å"], fallback=1)

    # –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π = —Å–ª–µ–¥—É—é—â–∞—è –∫–æ–ª–æ–Ω–∫–∞ –ø–æ—Å–ª–µ –ú–æ–¥—É–ª—å–ë–∞–Ω–∫
    comment_col = mb_col + 1 if mb_col + 1 < len(df_raw.columns) else None

    logger.info(
        f"–ñ—É—Ä–Ω–∞–ª: –î–∞—Ç–∞=col[{date_col}], –ú–æ–¥—É–ª—å–ë–∞–Ω–∫=col[{mb_col}], "
        f"–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π=col[{comment_col}]"
    )

    records = []
    for _, row in df_raw.iterrows():
        raw_date   = row.iloc[date_col]
        raw_amount = row.iloc[mb_col]
        raw_comment = row.iloc[comment_col] if comment_col is not None else ""

        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –±–µ–∑ –¥–∞—Ç—ã –∏–ª–∏ —Å—É–º–º—ã
        if pd.isna(raw_date) or pd.isna(raw_amount):
            continue

        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ (–±–∞–ª–∞–Ω—Å, —à–∞–ø–∫–∏)
        comment_str = str(raw_comment).strip()
        if any(kw in comment_str.lower() for kw in ["–±–∞–ª–∞–Ω—Å", "—Ç–µ–∫—É—â–∏–π", "–æ—Å—Ç–∞—Ç–æ–∫", "–∏—Ç–æ–≥–æ"]):
            continue

        try:
            dt = pd.to_datetime(raw_date, dayfirst=True).date()
        except Exception:
            continue

        try:
            amount = float(raw_amount)
        except (ValueError, TypeError):
            continue

        if amount == 0:
            continue

        records.append({"date": dt, "amount": amount, "comment": comment_str})

    result = pd.DataFrame(records)
    logger.info(f"–ñ—É—Ä–Ω–∞–ª: {len(result)} —Å—Ç—Ä–æ–∫ –ø–æ –ú–æ–¥—É–ª—å–ë–∞–Ω–∫ —Ä/—Å (–ø–µ—Ä–∏–æ–¥: {result['date'].min()} ‚Üí {result['date'].max()})")
    return result


def _find_col(df: pd.DataFrame, keywords: list[str], fallback: int) -> int:
    """–ò—â–µ—Ç –∫–æ–ª–æ–Ω–∫—É –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º –≤ –∏–º–µ–Ω–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω–¥–µ–∫—Å."""
    for i, col in enumerate(df.columns):
        col_l = str(col).lower().strip()
        if any(kw in col_l for kw in keywords):
            return i
    return fallback


# ‚îÄ‚îÄ 2. –ß–¢–ï–ù–ò–ï –ë–ê–ù–ö–û–í–°–ö–û–ô –í–´–ü–ò–°–ö–ò ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def read_bank_modulbank(bank_path: Path, owner_name: str = "") -> pd.DataFrame:
    """
    –ü–∞—Ä—Å–∏—Ç XLSX-–≤—ã–ø–∏—Å–∫—É –ú–æ–¥—É–ª—å–±–∞–Ω–∫–∞.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–π DataFrame:
        date | amount (+ –ø—Ä–∏—Ö–æ–¥ / ‚àí —Ä–∞—Å—Ö–æ–¥) | counterparty | purpose | type | category | subcategory
    """
    raw = parse_statement(bank_path)
    classifier = TransactionClassifier()

    records = []
    for _, row in raw.iterrows():
        cls = classifier.classify(row, owner_name=owner_name)
        signed = row["amount_in"] if row["is_income"] else -row["amount_out"]

        records.append(
            {
                "date":        row["date"].date(),
                "amount":      signed,
                "counterparty": row["counterparty"],
                "purpose":     row["purpose"],
                "type":        cls["type"],
                "category":    cls["category"],
                "subcategory": cls["subcategory"],
            }
        )

    result = pd.DataFrame(records)
    logger.info(f"–ë–∞–Ω–∫: {len(result)} —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π (–ø–µ—Ä–∏–æ–¥: {result['date'].min()} ‚Üí {result['date'].max()})")
    return result


# ‚îÄ‚îÄ 3. –°–û–ü–û–°–¢–ê–í–õ–ï–ù–ò–ï ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def match(
    journal: pd.DataFrame,
    bank: pd.DataFrame,
    start_date: date,
    tolerance: float = TOLERANCE,
) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:
    """
    –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –±–∞–Ω–∫–∞ –∏ –∂—É—Ä–Ω–∞–ª–∞ –∑–∞ –ø–µ—Ä–∏–æ–¥ [start_date, ‚àû).

    –ü—Ä–∞–≤–∏–ª–æ –º–∞—Ç—á–∞: date —Å–æ–≤–ø–∞–¥–∞–µ—Ç –ò abs(bank.amount ‚àí journal.amount) ‚â§ tolerance.

    Returns:
        matched       ‚Äî –µ—Å—Ç—å –≤ –æ–±–æ–∏—Ö
        missing       ‚Äî –µ—Å—Ç—å –≤ –±–∞–Ω–∫–µ, –Ω–µ—Ç –≤ –∂—É—Ä–Ω–∞–ª–µ ‚Üí –Ω—É–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å
        journal_only  ‚Äî –µ—Å—Ç—å –≤ –∂—É—Ä–Ω–∞–ª–µ, –Ω–µ—Ç –≤ –±–∞–Ω–∫–µ ‚Üí —Ä—É—á–Ω—ã–µ –∑–∞–ø–∏—Å–∏ / –¥—Ä—É–≥–æ–π –±–∞–Ω–∫
    """
    bank_p    = bank[bank["date"] >= start_date].copy().reset_index(drop=True)
    journal_p = journal[journal["date"] >= start_date].copy().reset_index(drop=True)

    logger.info(
        f"–°–≤–µ—Ä–∫–∞ —Å {start_date}: –±–∞–Ω–∫={len(bank_p)}, –∂—É—Ä–Ω–∞–ª={len(journal_p)}"
    )

    # –ú–Ω–æ–∂–µ—Å—Ç–≤–æ –µ—â—ë –Ω–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤ –∂—É—Ä–Ω–∞–ª–∞
    free_j = set(journal_p.index.tolist())

    matched_rows  = []
    missing_rows  = []

    for _, b in bank_p.iterrows():
        # –ò—â–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –≤ –∂—É—Ä–Ω–∞–ª–µ: —Ç–∞ –∂–µ –¥–∞—Ç–∞ + —Å—É–º–º–∞ ¬± tolerance
        candidates = journal_p[
            (journal_p.index.isin(free_j))
            & (journal_p["date"] == b["date"])
            & (abs(journal_p["amount"] - b["amount"]) <= tolerance)
        ]

        if not candidates.empty:
            j_idx = candidates.index[0]
            free_j.discard(j_idx)
            j = journal_p.loc[j_idx]

            matched_rows.append(
                {
                    "–î–∞—Ç–∞":              b["date"],
                    "–°—É–º–º–∞":             b["amount"],
                    "–¢–∏–ø":               b["type"],
                    "–ö–∞—Ç–µ–≥–æ—Ä–∏—è":         b["category"],
                    "–ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç (–±–∞–Ω–∫)": b["counterparty"],
                    "–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ (–±–∞–Ω–∫)": str(b["purpose"])[:80],
                    "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π (–∂—É—Ä–Ω–∞–ª)": j["comment"],
                }
            )
        else:
            missing_rows.append(
                {
                    "–î–∞—Ç–∞":                    b["date"],
                    "–°—É–º–º–∞":                   b["amount"],
                    "–¢–∏–ø":                     b["type"],
                    "–ö–∞—Ç–µ–≥–æ—Ä–∏—è":               b["category"],
                    "–ü–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è":            b["subcategory"],
                    "–ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç":              b["counterparty"],
                    "–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ –ø–ª–∞—Ç–µ–∂–∞":      str(b["purpose"])[:120],
                    "–ü—Ä–µ–¥–ª–∞–≥–∞–µ–º—ã–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π": _suggest_comment(b),
                }
            )

    journal_only_rows = [
        {
            "–î–∞—Ç–∞":    journal_p.loc[i, "date"],
            "–°—É–º–º–∞":   journal_p.loc[i, "amount"],
            "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π": journal_p.loc[i, "comment"],
            "–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ": "–ù–µ—Ç –≤ –±–∞–Ω–∫–æ–≤—Å–∫–æ–π –≤—ã–ø–∏—Å–∫–µ ‚Äî —Ä—É—á–Ω–∞—è –∑–∞–ø–∏—Å—å –∏–ª–∏ –¥—Ä—É–≥–æ–π –±–∞–Ω–∫",
        }
        for i in free_j
    ]

    return (
        pd.DataFrame(matched_rows),
        pd.DataFrame(missing_rows),
        pd.DataFrame(sorted(journal_only_rows, key=lambda r: r["–î–∞—Ç–∞"])),
    )


def _suggest_comment(b: pd.Series) -> str:
    """–§–æ—Ä–º–∏—Ä—É–µ—Ç –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º—ã–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –¥–ª—è –∂—É—Ä–Ω–∞–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö –±–∞–Ω–∫–∞."""
    cp = str(b.get("counterparty", ""))[:45]
    cat = b.get("category", "")
    purpose = str(b.get("purpose", ""))

    templates = {
        "–î–æ—Ö–æ–¥ ‚Äî Wildberries":       f"WB ‚Äî {cp}",
        "–î–æ—Ö–æ–¥ ‚Äî Ozon":              f"Ozon ‚Äî {cp}",
        "–ù–∞–ª–æ–≥–∏ –∏ —Å–±–æ—Ä—ã":            f"{b.get('subcategory', '–ù–∞–ª–æ–≥')} ‚Äî {purpose[:50]}",
        "–ë–∞–Ω–∫–æ–≤—Å–∫–∏–µ —Ä–∞—Å—Ö–æ–¥—ã":        f"–ö–æ–º–∏—Å—Å–∏—è ‚Äî {purpose[:50]}",
        "–§—É–ª—Ñ–∏–ª–º–µ–Ω—Ç":                f"–§—É–ª—Ñ–∏–ª–º–µ–Ω—Ç ‚Äî {cp}",
        "IT –∏ —Å–µ—Ä–≤–∏—Å—ã":              f"IT ‚Äî {cp}",
        "–ó–∞—Ä–ø–ª–∞—Ç–∞":                  f"–ó–∞—Ä–ø–ª–∞—Ç–∞ ‚Äî {cp}",
        "–°–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è":              f"–°–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è ‚Äî {cp}",
        "–ü–µ—Ä–µ–≤–æ–¥ (–≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π)":      f"–ü–µ—Ä–µ–≤–æ–¥ —Ä/—Å ‚Üí –ú–ö ‚Äî {purpose[:40]}",
        "–ü–µ—Ä–µ–≤–æ–¥ (–≤—ã–≤–æ–¥ –Ω–∞ –∫–∞—Ä—Ç—É)":  f"–í—ã–≤–æ–¥ ‚Üí {b.get('subcategory', cp)}",
        "–ó–∞–∫—É–ø–∫–∞ —Ç–æ–≤–∞—Ä–∞":            f"–¢–æ–≤–∞—Ä ‚Äî {cp}",
    }
    return templates.get(cat, f"{cp} ‚Äî {purpose[:40]}")


# ‚îÄ‚îÄ 4. –≠–ö–°–ü–û–†–¢ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def export(
    matched: pd.DataFrame,
    missing: pd.DataFrame,
    journal_only: pd.DataFrame,
    out_path: Path,
    entity: str,
    start_date: date,
) -> None:
    total_bank = len(matched) + len(missing)
    coverage_pct = (len(matched) / total_bank * 100) if total_bank else 0

    with pd.ExcelWriter(out_path, engine="openpyxl") as writer:
        # –õ–∏—Å—Ç 0 ‚Äî –ò—Ç–æ–≥–æ–≤–∞—è —Å–≤–æ–¥–∫–∞
        summary = pd.DataFrame(
            {
                "–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å": [
                    "–Æ—Ä–ª–∏—Ü–æ",
                    "–ü–µ—Ä–∏–æ–¥ —Å–≤–µ—Ä–∫–∏ (–Ω–∞—á–∞–ª–æ)",
                    "–û–ø–µ—Ä–∞—Ü–∏–π –≤ –±–∞–Ω–∫–µ (–∑–∞ –ø–µ—Ä–∏–æ–¥)",
                    "‚úÖ –ù–∞–π–¥–µ–Ω–æ –≤ –∂—É—Ä–Ω–∞–ª–µ",
                    "‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –∂—É—Ä–Ω–∞–ª–µ",
                    "‚ö†Ô∏è  –¢–æ–ª—å–∫–æ –≤ –∂—É—Ä–Ω–∞–ª–µ (—Ä—É—á–Ω–æ–π –≤–≤–æ–¥)",
                    "–ü–æ–∫—Ä—ã—Ç–∏–µ –∂—É—Ä–Ω–∞–ª–∞",
                    "",
                    "–°—É–º–º–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö (–±–µ–∑ –ø–µ—Ä–µ–≤–æ–¥–æ–≤)",
                ],
                "–ó–Ω–∞—á–µ–Ω–∏–µ": [
                    entity,
                    str(start_date),
                    total_bank,
                    len(matched),
                    len(missing),
                    len(journal_only),
                    f"{coverage_pct:.1f}%",
                    "",
                    _missing_pnl_sum(missing),
                ],
            }
        )
        summary.to_excel(writer, sheet_name="üìä –°–≤–æ–¥–∫–∞", index=False)

        # –õ–∏—Å—Ç 1 ‚Äî –ì–ª–∞–≤–Ω–æ–µ: —á–µ–≥–æ –Ω–µ—Ç –≤ –∂—É—Ä–Ω–∞–ª–µ
        if not missing.empty:
            missing.sort_values("–î–∞—Ç–∞").to_excel(
                writer, sheet_name="‚ùå –ù–µ—Ç –≤ –∂—É—Ä–Ω–∞–ª–µ", index=False
            )

        # –õ–∏—Å—Ç 2 ‚Äî –°–æ–≤–ø–∞–¥–µ–Ω–∏—è
        if not matched.empty:
            matched.sort_values("–î–∞—Ç–∞").to_excel(
                writer, sheet_name="‚úÖ –°–æ–≤–ø–∞–¥–∞—é—Ç", index=False
            )

        # –õ–∏—Å—Ç 3 ‚Äî –¢–æ–ª—å–∫–æ –≤ –∂—É—Ä–Ω–∞–ª–µ
        if not journal_only.empty:
            pd.DataFrame(journal_only).sort_values("–î–∞—Ç–∞").to_excel(
                writer, sheet_name="‚ö†Ô∏è –¢–æ–ª—å–∫–æ –≤ –∂—É—Ä–Ω–∞–ª–µ", index=False
            )

        # –ê–≤—Ç–æ-—à–∏—Ä–∏–Ω–∞ –∫–æ–ª–æ–Ω–æ–∫
        for ws in writer.sheets.values():
            for col in ws.columns:
                w = max(len(str(c.value or "")) for c in col)
                ws.column_dimensions[col[0].column_letter].width = min(w + 2, 55)

    logger.info(f"–û—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {out_path}")


def _missing_pnl_sum(missing: pd.DataFrame) -> str:
    """–°—É–º–º–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏–π, –≤–ª–∏—è—é—â–∏—Ö –Ω–∞ P&L (–±–µ–∑ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –ø–µ—Ä–µ–≤–æ–¥–æ–≤)."""
    if missing.empty:
        return "0"
    pnl = missing[~missing["–¢–∏–ø"].str.startswith("–ü–µ—Ä–µ–≤–æ–¥", na=False)]
    total = pnl["–°—É–º–º–∞"].sum()
    return f"{total:,.0f} —Ä—É–±."


# ‚îÄ‚îÄ 5. MAIN ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def main() -> None:
    p = argparse.ArgumentParser(description="–°–≤–µ—Ä–∫–∞ –∂—É—Ä–Ω–∞–ª–∞ —Å –±–∞–Ω–∫–æ–≤—Å–∫–æ–π –≤—ã–ø–∏—Å–∫–æ–π")
    p.add_argument("--bank",    required=True, help="–ü—É—Ç—å –∫ XLSX-–≤—ã–ø–∏—Å–∫–µ –±–∞–Ω–∫–∞")
    p.add_argument("--journal", required=True, help="–ü—É—Ç—å –∫ XLSX-–∂—É—Ä–Ω–∞–ª—É –æ–ø–µ—Ä–∞—Ü–∏–π")
    p.add_argument("--entity",  default="UNKNOWN")
    p.add_argument("--owner",   default="", help='–§–ò–û –≤–ª–∞–¥–µ–ª—å—Ü–∞ —Ä/—Å (–¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–µ—Ä–µ–≤–æ–¥–æ–≤)')
    p.add_argument("--out",     default=None)
    args = p.parse_args()

    bank_path    = Path(args.bank)
    journal_path = Path(args.journal)
    out_path     = Path(args.out) if args.out else Path(f"diff_{args.entity}.xlsx")

    for f in [bank_path, journal_path]:
        if not f.exists():
            logger.error(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {f}")
            sys.exit(1)

    # –ß–∏—Ç–∞–µ–º
    journal_df = read_journal_modulbank(journal_path)
    bank_df    = read_bank_modulbank(bank_path, owner_name=args.owner)

    if journal_df.empty:
        logger.error("–ñ—É—Ä–Ω–∞–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –ú–æ–¥—É–ª—å–ë–∞–Ω–∫ —Ä/—Å")
        sys.exit(1)

    # –ü–µ—Ä–∏–æ–¥ —Å–≤–µ—Ä–∫–∏ = —Å –ø–µ—Ä–≤–æ–π –¥–∞—Ç—ã –≤ –∂—É—Ä–Ω–∞–ª–µ
    start_date = journal_df["date"].min()

    # –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º
    matched, missing, journal_only = match(journal_df, bank_df, start_date)

    # –ö–æ–Ω—Å–æ–ª—å–Ω—ã–π –≤—ã–≤–æ–¥
    total_bank = len(matched) + len(missing)
    cov = len(matched) / total_bank * 100 if total_bank else 0

    print(f"\n{'='*58}")
    print(f"  –°–≤–µ—Ä–∫–∞ | {args.entity} | —Å {start_date}")
    print(f"{'='*58}")
    print(f"  –û–ø–µ—Ä–∞—Ü–∏–π –≤ –±–∞–Ω–∫–µ –∑–∞ –ø–µ—Ä–∏–æ–¥:     {total_bank:>4}")
    print(f"  –ù–∞–π–¥–µ–Ω–æ –≤ –∂—É—Ä–Ω–∞–ª–µ       ‚úÖ:     {len(matched):>4}  ({cov:.0f}%)")
    print(f"  –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ –∂—É—Ä–Ω–∞–ª–µ   ‚ùå:     {len(missing):>4}")
    print(f"  –¢–æ–ª—å–∫–æ –≤ –∂—É—Ä–Ω–∞–ª–µ        ‚ö†Ô∏è:     {len(journal_only):>4}")
    print(f"{'='*58}")

    if not missing.empty:
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–∏–ø—É
        by_type = missing.groupby("–¢–∏–ø")["–°—É–º–º–∞"].agg(["count", "sum"])
        print("\n–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–æ —Ç–∏–ø—É:")
        for t, row in by_type.iterrows():
            print(f"  {t:<35} {int(row['count']):>3} —à—Ç.  {row['sum']:>14,.0f} —Ä—É–±.")

        print("\n–¢–æ–ø-10 –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö (–ø–æ |—Å—É–º–º–µ|):")
        top10 = missing.reindex(
            missing["–°—É–º–º–∞"].abs().sort_values(ascending=False).index
        ).head(10)
        for _, r in top10.iterrows():
            sign = "+" if r["–°—É–º–º–∞"] > 0 else ""
            print(
                f"  {r['–î–∞—Ç–∞']}  {sign}{r['–°—É–º–º–∞']:>12,.0f}  "
                f"{r['–ö–∞—Ç–µ–≥–æ—Ä–∏—è']:<28} {str(r['–ö–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç'])[:35]}"
            )

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    export(matched, missing, journal_only, out_path, args.entity, start_date)
    print(f"\n‚úÖ –û—Ç—á—ë—Ç: {out_path.resolve()}\n")


if __name__ == "__main__":
    main()
